{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOdE5OIfx3h4ERIYSFHNR+4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Lesson 1: Tensorflow Basics"
      ],
      "metadata": {
        "id": "qSxyExA5YY7J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "pAIjPTbRVvrc"
      },
      "outputs": [],
      "source": [
        "# @title imports!\n",
        "# !pip install \n",
        "\n",
        "import torch\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# basic tensors\n",
        "t1 = torch.tensor(4.) # float32\n",
        "t2 = torch.tensor([1, 2, 3, 4]) # vector\n",
        "t3 = torch.tensor([[5., 6.], [7., 8.], [9., 10.]]) # matrix\n",
        "\n",
        "# tensor operations\n",
        "x = torch.tensor(3.)\n",
        "w = torch.tensor(4., requires_grad=True)\n",
        "b = torch.tensor(5., requires_grad=True)\n",
        "y = w * x + b\n",
        "# print(y)\n",
        "\n",
        "# compute derivatives\n",
        "y.backward()\n",
        "\n",
        "# display gradients\n",
        "print(\"dy/dx:\", x.grad)\n",
        "print(\"dy/dw:\", w.grad) # has the same value as x, ie. 3 \n",
        "print(\"dy/db:\", b.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3v5CVEFKWUgP",
        "outputId": "eb0c4863-0c78-4ad9-e6cd-463f4da03b5f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dy/dx: None\n",
            "dy/dw: tensor(3.)\n",
            "dy/db: tensor(1.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# inter-op with numpy\n",
        "\n",
        "a1 = np.array([[1, 2], [3, 4]])\n",
        "ten1 = torch.from_numpy(x)"
      ],
      "metadata": {
        "id": "hxAj0fykX-aQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lesson 2 - Linear Regression"
      ],
      "metadata": {
        "id": "5glWa40NYgL_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch"
      ],
      "metadata": {
        "id": "k7AUAQXvYj22"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# input (temp, rainfall, humidity)\n",
        "inputs = np.array([[73, 67, 43], \n",
        "                   [91, 88, 64], \n",
        "                   [87, 134, 58], \n",
        "                   [102, 43, 37], \n",
        "                   [69, 96, 70]], dtype='float32')\n",
        "targets = np.array([[56, 70], \n",
        "                    [81, 101], \n",
        "                    [119, 133], \n",
        "                    [22, 37], \n",
        "                    [103, 119]], dtype='float32')\n",
        "\n",
        "inputs = torch.from_numpy(inputs)\n",
        "targets = torch.from_numpy(targets)\n",
        "# print(inputs)\n",
        "# print(targets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-K1Um2_ZBU3",
        "outputId": "0f0b31e0-66b0-4b5e-fbfc-4b8c0870b4c4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 73.,  67.,  43.],\n",
            "        [ 91.,  88.,  64.],\n",
            "        [ 87., 134.,  58.],\n",
            "        [102.,  43.,  37.],\n",
            "        [ 69.,  96.,  70.]])\n",
            "tensor([[ 56.,  70.],\n",
            "        [ 81., 101.],\n",
            "        [119., 133.],\n",
            "        [ 22.,  37.],\n",
            "        [103., 119.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# linear regression model from scratch\n",
        "\n",
        "# weights and biases\n",
        "w = torch.randn(2, 3, requires_grad=True) # 2 row, 3 column matrix of random values\n",
        "b = torch.randn(2, requires_grad=True) # 2 row, 1 column matrix of random values"
      ],
      "metadata": {
        "id": "ixKU8i8ebF2L"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**note:** random values are picked from a normal distribution with mean 0 and standard deviation 1."
      ],
      "metadata": {
        "id": "kepsETH2bdlb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# linear regression model, simply a Y = mX + C thing\n",
        "def model(x):\n",
        "  return x @ w.t() + b # (@ represents matrix multiplication)\n",
        "\n",
        "# generate predictions\n",
        "preds = model(inputs)\n",
        "print(preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wN51r80lb3fM",
        "outputId": "bd37803d-681d-4595-e527-177d779790a6"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 60.3191, -27.1181],\n",
            "        [ 78.6981, -51.4230],\n",
            "        [ 74.2860, -69.9580],\n",
            "        [ 76.5674,  20.0796],\n",
            "        [ 66.8297, -84.0901]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(targets) # compare our prediction with the target values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bw1OPnHhc3wV",
        "outputId": "eeac1c53-b67e-4be3-9e4d-db1fb3f21a5a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 56.,  70.],\n",
            "        [ 81., 101.],\n",
            "        [119., 133.],\n",
            "        [ 22.,  37.],\n",
            "        [103., 119.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loss function (mean squared error - mse)\n",
        "def mse(t1, t2):\n",
        "  diff = t1 - t2\n",
        "  return torch.sum(diff * diff) / diff.numel()\n",
        "\n",
        "loss = mse(preds, targets)\n",
        "print(\"loss:\", loss)\n",
        "\n",
        "# compute gradients of the loss wrt. weights and biases\n",
        "loss.backward()\n",
        "print(w)\n",
        "print(w.grad) # gradients for weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQsvxT-0c7cG",
        "outputId": "afa3855c-1577-47ca-bc23-e6b36fb3bc50"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: tensor(12169.7676, grad_fn=<DivBackward0>)\n",
            "tensor([[ 0.6309,  0.0023,  0.3322],\n",
            "        [ 0.9101, -0.5100, -1.4275]], requires_grad=True)\n",
            "tensor([[  -142.8349,  -1406.1621,   -613.5878],\n",
            "        [-10871.3105, -13468.1465,  -8109.0142]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# modify weights and biases\n",
        "with torch.no_grad():\n",
        "  w -= w.grad * 1e-5 # 1e-5 to make sure the weights aren't updated too much at a time\n",
        "  b -= b.grad * 1e-5\n",
        "\n",
        "loss = mse(preds, targets)\n",
        "print(\"new loss:\", loss) # let's check that the loss is lower!\n",
        "\n",
        "# reset gradients to 0 before proceeding\n",
        "w.grad.zero_()\n",
        "b.grad.zero_()\n",
        "print(w.grad, b.grad) # the gradients are reset!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRxV_bUfe_WZ",
        "outputId": "939e4cd2-3af4-4bd3-8334-573d47879560"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new loss: tensor(12169.7676, grad_fn=<DivBackward0>)\n",
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]]) tensor([0., 0.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title train the model using gradient descent!\n",
        "\n",
        "preds = model(inputs)\n",
        "print(preds)\n",
        "\n",
        "# calc loss\n",
        "loss = mse(preds, targets)\n",
        "print(loss) # @markdown the loss should be better than last time!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSehKTWSgQ_m",
        "outputId": "0896d58d-9e07-41d2-8390-15a18b7356e6"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[64.2500, 34.2258],\n",
            "        [83.9785, 29.3849],\n",
            "        [81.3794, 26.6718],\n",
            "        [79.4996, 79.7248],\n",
            "        [72.4638, -5.7652]], grad_fn=<AddBackward0>)\n",
            "tensor(4083.6875, grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title training for multiple epochs\n",
        "for i in range(10000):\n",
        "  preds = model(inputs)\n",
        "  loss = mse(preds, targets)\n",
        "  loss.backward()\n",
        "  with torch.no_grad():\n",
        "    w -= w.grad * 1e-5\n",
        "    b -= b.grad * 1e-5\n",
        "\n",
        "    w.grad.zero_()\n",
        "    b.grad.zero_()\n",
        "  \n",
        "# and then calculate the loss\n",
        "preds = model(inputs)\n",
        "loss = mse(preds, targets)\n",
        "print(\"final preds:\\n\", preds)\n",
        "print(\"final loss:\\n\", loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSAkB_7ch6kI",
        "outputId": "2ffd5b9e-26cd-41a5-d7ed-eb09a2428db9"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "final preds:\n",
            " tensor([[ 57.1353,  70.6433],\n",
            "        [ 82.2256, 100.4605],\n",
            "        [118.6980, 132.9042],\n",
            "        [ 21.0852,  36.9732],\n",
            "        [101.9156, 119.1914]], grad_fn=<AddBackward0>)\n",
            "final loss:\n",
            " tensor(0.5646, grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    }
  ]
}